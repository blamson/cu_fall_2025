)
})
mean(c(Tsim, Tobs) >= Tobs)
h <- seq(from=0, to=0.25, length.out=200)
Tobs <- max(spatstat.explore::Lest(pines, correction = "Ripley")$iso - h)
pine_l <-
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
max(spatstat.explore::Lest(pines, r=h, correction = "Ripley")$iso - h)
})
mean(c(Tsim, Tobs) >= Tobs)
h <- seq(from=0, to=0.25, length.out=200)
Tobs <- max(spatstat.explore::Lest(pines, correction = "Ripley")$iso - h)
pine_l <-
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
max(spatstat.explore::Lest(pines, r=h, correction = "Ripley")$iso - h)
})
mean(c(Tsim, Tobs) >= Tobs)
Tsim
h
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
max(spatstat.explore::Lest(pines, r=h, correction = "Ripley")$iso - h)
})
mean(c(Tsim, Tobs) >= Tobs)
Tobs
Window(pines)
1:499
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
i
})
mean(c(Tsim, Tobs) >= Tobs)
Tsim
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
1
})
mean(c(Tsim, Tobs) >= Tobs)
Tsim
intensity(pines)
length(pines)
length(pines$x)
pines$n
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(lambda=pines$n, win = spatstat.geom::Window(pines))
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
mean(c(Tsim, Tobs) >= Tobs)
area(Window(pines))
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
pines_window <- spatstat.geom::Window(pines)
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=pines$n * spatstat.geom::area(pines_window),
win = pines_window
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
mean(c(Tsim, Tobs) >= Tobs)
Tsim
density(pines)
density(pines)$v
intensity(pines)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
mean(c(Tsim, Tobs) >= Tobs)
Tsim
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
mean(c(Tsim, Tobs) >= Tobs)
Tsim
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
mean(c(Tsim, Tobs) >= Tobs)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
p <- mean(c(Tsim, Tobs) >= Tobs)
cat("P-Value: ", p)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
p <- mean(c(Tsim, Tobs) >= Tobs)
cat("P-Value:", p)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# For Tsim we want to... simulate our data somehow right?
# We want to create 499 simulated datasets and compute \hat{L}(h) - h for those sims
# So we want to simulate CSR data in the same study area AS the pines dataset.
# For this we can use the Window(pines) function to extract the study area from pines
# And generate CSR data in that space.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
p <- mean(c(Tsim, Tobs) >= Tobs)
cat("P-Value:", p)
c(Tsim, Tobs) >= Tobs
cat("P-Value:", p)
#| code-fold: true
#| code-summary: The code
set.seed(500)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max(L_obs$iso - h)
# Do the same setup for the simulated datasets.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max(sim_L$iso - h)
})
# We make sure to include our observed data in the p-value.
p <- mean(c(Tsim, Tobs) >= Tobs)
cat("P-Value:", p)
#| code-fold: true
#| code-summary: The code
set.seed(500)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max( abs(L_obs$iso - h) )
# Do the same setup for the simulated datasets.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max( abs(sim_L$iso - h) )
})
# We make sure to include our observed data in the p-value.
p <- mean(c(Tsim, Tobs) >= Tobs)
cat("P-Value:", p)
Tsim
c(Tsim, Tobs) >= Tobs
abs(-5)
plot(Tsim)
plot(density(Tsim))
plot(density(Tsim))
Tobs
summary(Tsim)
1/500
T_obs
Tobs
#| code-fold: true
#| code-summary: Make a plot for my own sake
plot(density(Tsim),
main = "Monte Carlo Test Statistic Distribution",
xlab = "Max - Min Intensity")
abline(v = Tobs, col = "red", lty = 2, lwd = 2)
#| code-fold: true
#| code-summary: Make a plot for my own sake
plot(density(Tsim),
main = "Monte Carlo Test Statistic Distribution",
xlab = "Max - Min Intensity")
abline(v = Tobs, col = "red", lty = 2, lwd = 2)
Tobs
#| code-fold: true
#| code-summary: Make a plot for my own sake
plot(density(Tsim),
main = "Monte Carlo Test Statistic Distribution",
xlab = "Max - Min Intensity")
abline(v = Tobs, col = "red", lty = 2, lwd = 2)
#| code-fold: true
#| code-summary: Make a plot for my own sake
plot(density(Tsim),
main = "Monte Carlo Test Statistic Distribution",
xlab = "T")
abline(v = Tobs, col = "red", lty = 2, lwd = 2)
#| code-fold: true
#| code-summary: Make a plot for my own sake
plot(density(Tsim),
xlim = range(c(Tsim, Tobs)),
main = "Monte Carlo Test Statistic Distribution",
xlab = "T")
abline(v = Tobs, col = "red", lty = 2, lwd = 2)
#| code-fold: true
#| code-summary: The code
set.seed(500)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, r=h, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max( abs(L_obs$iso - h) )
# Do the same setup for the simulated datasets.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max( abs(sim_L$iso - h) )
})
# We make sure to include our observed data in the p-value.
p <- mean(c(Tsim, Tobs) >= Tobs)
cat("P-Value:", p)
#| code-fold: true
#| code-summary: Make a plot for my own sake
plot(density(Tsim),
xlim = range(c(Tsim, Tobs)),
main = "Monte Carlo Test Statistic Distribution",
xlab = "T")
abline(v = Tobs, col = "red", lty = 2, lwd = 2)
set.seed(1)
# load packages
library(smacpod)
data(grave)
# selection to graves that are affected
af = which(grave$marks == "affected")
# estimate densities of cases and controls, respectively,
# using bandwidth of 700
f700 = spdensity(grave[af, ], sigma = 700)
g700 = spdensity(grave[-af,], sigma = 700)
g700
# contour plot of f700 with title
contour(f700, nlevels = 15, main = "")
title("Affected, bandwidth = 700")
contour(g700, nlevels = 15, main = "")
title("Nonaffected, bandwidth = 700")
r700 = logrr(grave, case = "affected", sigma = 700)
# contour plot of r700 (lty and lwd determined
# by experimentation)
contour(r700, lty = c(1, 1, 1, 1, 2, 1),
lwd = c(1, 1, 1, 1, 1, 2), main = "")
title("Gaussian kernel, Bandwidth = 700")
logrr
# calculate log ratio of spatial densities for bandwidth = 350
f350 = spdensity(grave[af, ], sigma = 350)
g350 = spdensity(grave[-af,], sigma = 350)
r350 = logrr(grave, case = "affected", sigma = 350)
# contour plot of log ratio of spatial densities
contour(r350, lty = c(2, 1, 1, 1, 1), main = "")
# construct 95% tolerance envelopes for log relative risk
# when bandwidth = 350
if (!file.exists("renv350.rda")) {
renv350 = logrr(grave, sigma = 350, case = "affected",
nsim = 999, level = 0.95)
save(renv350, file = "renv350.rda")
}
load("renv350.rda")
# image plot showing regions where r350 is outside
# tolerance envelopes
plot(renv350)
grad = gradient.color.scale(min(renv350$v, na.rm = TRUE),
max(renv350$v, na.rm = TRUE))
plot(renv350, col = grad$col, breaks = grad$breaks)
## global test that spatial densities of cases/controls
# are the same
logrr.test(renv350)
redwood <- spatstat.data::redwood
redwood
packages <- c("spatstat", "pbapply", "smacpod")
for (pkg in packages) {
if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
install.packages(pkg, repos = "https://cran.rstudio.com/")
library(pkg, character.only = TRUE)
}
}
pines <- spatstat.data::japanesepines
#| code-fold: true
#| code-summary: The code
lplot <- function(x, nsim = 499, level = 0.95,
correction = "Ripley", ...) {
e_outer = envelope(x, fun = spatstat.explore::Lest,
nsim = nsim, nrank = 1,
savepatterns = TRUE)
e_tol = envelope(e_outer, fun = spatstat.explore::Lest,
nsim = nsim,
nrank = floor((1 - level) * (nsim + 1)/2))
plot(e_outer, fmla = . - r ~ r, legend = FALSE, main = "")
plot(e_tol, fmla = . - r ~ r, shadecol = "lightgrey", add = TRUE)
}
lplot(pines)
#| code-fold: true
#| code-summary: The code
set.seed(500)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(pines, r=h, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max( abs(L_obs$iso - h) )
# Do the same setup for the simulated datasets.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(pines),
win = spatstat.geom::Window(pines)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max( abs(sim_L$iso - h) )
})
# We make sure to include our observed data in the p-value.
p <- mean(c(Tsim, Tobs) >= Tobs)
cat("P-Value:", p)
#| code-fold: true
#| code-summary: Make a plot for my own sake
plot(density(Tsim),
xlim = range(c(Tsim, Tobs)),
main = "Monte Carlo Test Statistic Distribution",
xlab = "T")
abline(v = Tobs, col = "red", lty = 2, lwd = 2)
redwood <- spatstat.data::redwood
plot(redwood)
bandwidth <- spatstat.explore::bw.scott(redwood)
intensity_est <- smacpod::spdensity(redwood, sigma = bandwidth)
contour(intensity_est)
lplot(redwood)
#| code-fold: true
#| code-summary: The code
set.seed(500)
h <- seq(from=0, to=0.25, length.out=200)
# Break out \hat{L}(h) just for readability
L_obs <- spatstat.explore::Lest(redwood, r=h, correction = "Ripley")
# Calc observed test statistic across h
Tobs <- max( abs(L_obs$iso - h) )
# Do the same setup for the simulated datasets.
Tsim <- pbapply::pbsapply(1:499, FUN = function(i) {
sim_data <- spatstat.random::rpoispp(
lambda=spatstat.geom::intensity(redwood),
win = spatstat.geom::Window(redwood)
)
sim_L <- spatstat.explore::Lest(sim_data, r=h, correction = "Ripley")
max( abs(sim_L$iso - h) )
})
# We make sure to include our observed data in the p-value.
p <- mean(c(Tsim, Tobs) >= Tobs)
p
cat("P-Value:", p)
set.seed(1)
x <- runif(15)
h <- seq(-1, 2, len = 1000)
dnorm(x, sd=h)
h
dnorm(h, mean=x, sd=0.1)
# (i) Evaluate Gaussian kernel (sd = 0.1) at each event location
kernels <- sapply(x, function(xi) dnorm(h, mean = xi, sd = 0.10))
kernels
kernels[1]
kernels[1,]
typeof(kernels)
View(kernels)
# (ii) Sum across rows
rowSums(kernels)
# (i) Evaluate Gaussian kernel (sd = 0.1) at each event location
# Object is 1000 rows by 15 columns
kernels <- sapply(x, function(xi) dnorm(h, mean = xi, sd = 0.10))
# (ii) Sum across rows
kernel_sums <- rowSums(kernels)
plot(kernel_sums)
plot(kernel_sums)
matlines(h, kernels, lty = 1, col = "gray")
plot(kernel_sums, type="l")
matlines(h, kernels, lty = 1, col = "gray")
plot(kernel_sums, type="l", lwd=2)
matlines(h, kernels, lty = 1, col = "gray")
sim(kernels)
dim(kernels)
plot(x=h, y=kernel_sums, type="l", lwd=2)
matlines(h, kernels, lty = 1, col = "gray")
plot(x=h, y=kernel_sums, type="l", lwd=2)
matlines(h, kernels, lty = 1, col = "blue")
plot(x=h, y=kernel_sums, type="l", lwd=2)
matlines(h, kernels, lty = 1, col = "lightgrey")
plot(x=h, y=kernel_sums, type="l", lwd=2)
matlines(h, kernels, lty = 1, col = "darkgrey")
# (i) Evaluate Gaussian kernel (sd = 0.1) at each event location
# Object is 1000 rows by 15 columns
kernels <- sapply(x, function(xi) dnorm(h, mean = xi, sd = 0.10))
# (ii) Sum across rows
kernel_sums <- rowSums(kernels)
plot(x=h, y=kernel_sums, type="l", lwd=2)
matlines(h, kernels, lty = 1, col = "darkgrey")
# (i) Evaluate Gaussian kernel (sd = 0.1) at each event location
# Object is 1000 rows by 15 columns
kernels <- sapply(x, function(xi) dnorm(h, mean = xi, sd = 0.25))
# (ii) Sum across rows
kernel_sums <- rowSums(kernels)
plot(x=h, y=kernel_sums, type="l", lwd=2)
matlines(h, kernels, lty = 1, col = "darkgrey")
